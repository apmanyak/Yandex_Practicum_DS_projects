# Прогнозирование оттока клиента Банка


## Описание проекта

Из банка стали уходить клиенты. 

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Необходимо построить модель с предельно большим значением *F1*-меры (до 0.59).

Дополнительно измеряем *AUC-ROC*, сравниваем её значение с *F1*-мерой.


## Навыки и инструменты

- **python**
- **pandas**
- **matplotlib**

- **scikit-learn**
   - from sklearn.tree import DecisionTreeClassifier
   - from sklearn.ensemble import RandomForestClassifier
   - from sklearn.linear_model import LogisticRegression 
   - from sklearn.model_selection import train_test_split 
   - from sklearn.preprocessing import (
    OneHotEncoder,
    StandardScaler)
   - from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    recall_score,
    precision_score,
    f1_score,
    precision_recall_curve,
    roc_auc_score,
    roc_curve
)
  - from sklearn.utils import shuffle

## Вывод

В рамках проекта мною были выполнены следующие шаги:

* **Шаг 1**

На выходе получили таблицу с значением 9091 строк и 11 колонок. В процессе подготовки данных скорректировали оформление у названий столбцов, удалили строки с пропусками в столбце tenure. 9.09% строк от визначального датасфрейма было удалено. Была выявлена зависимости, что строки присудствовали в равных пропорциях различных категориях и было принято решение из удлаить, так как это не приведет к резкому смещению значений во всем датафрейма.

Так же были удалены столбцы:'index','RowNumber', 'CustomerId', 'Surname'. Причина: отсутсвие полезной информации для построения модели и возможности влияние на обучение в негативную сторону.

Наблюдается неравномерное распредление данных в 'geography','num_of_products', 'has_cr_card', 'exited','balance'.
Очень сильно в 'balance'. Болшое кол-во знначений около нуля.

Столбцы с категоральными данными: 'geography','gender'. Было выполнено прямое кодирование с данным столбцами.
Также выполнено масштабирование в оставшихся числовыых столбцах.

Разделение исходных данных на обучающую, валидационную и тестовую выборки.
Исходные данные разбивают в соотношении 3:1:1.
Под обучающие данные мы выделили 60%. Под валидационную часть 20% и под тестовую часть тоже 20%

В целевом признаке exited ярко выражен дисбаланс классов. Наиболее часто всречается значение с 0 (79% составляет от всех данных в признаке)

* **Шаг 2**

Был выполнен поиск наилучшй модели. Ею оказался Решающее дерево при значениях гиперпараметров:

- Лучшая max_depth: 6

Также был проведен анализ модели на адекватность и выявлено, что модель имеет дисбаланс данных в целевом признаке

А метрики дают следующие значения: 
- Полнота: 0.46153846153846156
- Точность: 0.7837837837837838
- F1 мера: 0.5809682804674458
- AUC-ROC : 0.844938

Т.к. точность определяет, как много отрицательных ответов нашла модель, пока искала положительные. И внашем случае точность получилоь достаточно высокой
Полнота выявляет, какую долю положительных среди всех ответов выделила модель. Можно наблюдать, что их меньше половины. 

Показатели f1 необходимо повысить.


* **Шаг 3**

Было 2 способа борьбы способы с дисбалансом:
- 1) применив class_weight='balanced' в моеделях: Дерево решений, Случайный лес, Линейная регрессия.

| Метрики             | Дерево решений           |  Случайны лес       |  Линейная регрессия  |  
| :---               | :----                   | :----            | :----                  |  
|  Accuary           |     0.7871287128712872           |0.8443344334433444                |0.7090209020902091               |
| F1                 |       0.5420118343195266         |0.6466916354556803                 |0.5004721435316335               |
| Полнота (recall)    |       -         |0.6870026525198939                |-              |
| Точность (precision)|      -          |0.6108490566037735          |-               |
| AUC-ROC            |      -         |0.8665861645593155               | -              |
 


Лучшей оказалась модель случайного леса по параметрам F1

Гиперпараметры:
- Лучшая max_depth: 9
- Лучшая n_estimators: 45


- 2) увеличение выборки. Рассмотрено на модели случайны лес. 


| Метрики             | Случайный лес (class_weight=balanced)          |Случайный лес (увеличение выборки) |
| :---                | :----                           |:----                            |
|  Accuary            |     0.844334         |     0.813531          |
| F1                  |       0.646692        |     0.626240         |
| Полнота (recall)    |       0.866586         |     0.868178          |
| Точность (precision)|      0.6870026525198939         |     0.753315649867374         |
| AUC-ROC             |      0.6108490566037735         |     0.5358490566037736          |



Таким образом,исправление дисбаланса классов в target_train повысило качетво модели.

Гиперпараметры:
- Лучшая max_depth: 8
- Лучшая n_estimators: 25

Проведем тестирование модели. Тестирование Будем проводить на модели Случайны лес применив class_weight='balanced' и с гиперпараметрами:
- Лучшая max_depth: 9
- Лучшая n_estimators: 45
Так как значение f1 метрики у нее  оказалось выше.

* **Шаг 4**

На тестовой выборке получились следующе значения:


| Метрики             | class_weight='balanced'          |  
| :---               | :----                   | 
|  Accuary           |     0.8416712479384277           |      
| F1                 |       0.6118598382749326        |
| Полнота (recall)    |       0.6467236467236467         |
| Точность (precision)|      0.5805626598465473          |
| AUC-ROC            |      0.8563388372652678         | 


Таким образом модель случанйый лес дает необходиоме значение F1 выше 0,59 с борьбой диссбаланса с помощью  class_weight='balanced' и с гиперпараметрами:
- Лучшая max_depth: 9
- Лучшая n_estimators: 45

