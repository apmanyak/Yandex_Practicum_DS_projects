# Построение модели определения стоимости автомобиля



## Описание проекта

Сервис по продаже автомобилей с пробегом  разрабатывает приложение для привлечения новых клиентов. В нём можно быстро узнать рыночную стоимость своего автомобиля. На основе исторические данные необходимо построить модель для определения стоимости автомобиля.

Заказчику важны для построение модели:

- качество предсказания;
- скорость предсказания;
- время обучения.


## Навыки и инструменты

- **python**
- **pandas**
- **matplotlib**
- **numpy**
- **seaborn**
- **scikit-learn**
  - from sklearn.model_selection import (
    GridSearchCV, 
    RandomizedSearchCV,
    train_test_split,
    cross_val_score
)
  - from sklearn.compose import make_column_transformer
  - from sklearn.pipeline import make_pipeline

  - from sklearn.preprocessing import (
    OneHotEncoder,
    StandardScaler
)
  - from sklearn.linear_model import (
    LinearRegression, 
    Ridge
    )
  - from sklearn.metrics import (
    mean_squared_error,
    make_scorer
)
- **lightgbm**
- **catboost**

## Вывод

Для выполнения данного проекта были выполнены следущие шаги:

- ШАГ 1

В данном шаге была выполнена подготовка данных к исследованиям.
В ходы подготовки было сделано:
1. перевод названий столбцов к нижнему регистру
2. посчитано кол-во пропущенных строк и их процент от всех строк 

| Наименование столбца  | Кол-во пустых строк | Процент пустых строк |
| :---               | :----             | :---    |
| Repaired         | 71154              | 20.079070 |
| VehicleType       | 37490              | 10.579368 |
| FuelType             | 32895              | 9.282697 |
| Gearbox    | 19833               | 5.596709 |
| Model               | 19705                 | 5.560588 |

3. пустые значения в столбцах выше было принято решение заменить в Repaired на 0, 'yes' заменили на 1. В 'Gearbox' на 'manual'. в остальных на 'other'. Пропуски наблюдались только в категорийных признаках.
4. Избавились от уникальных дупликатов.
5. Избавились от неинформативных столбцов в признаках, а именно: 'date_crawled', 'date_created','number_of_pictures','postal_code', 'last_seen', 'registration_month'
6. Данные очистили от выбросов в 'power', 'price'.
7. Также удалил строки в которых пропущенные значения наблюдались сразу в нескольких столбцах

Процент потерянных строк всего датасета  по итогу обработки данных: 17.74449796680861 %

Было:

- Строк: 354369
- Столбцов: 16

Стало 
- Строк: 291488
- Столбцов: 10


- ШАГ 2

В данном проекте были рассмотрены 4 модели машинного обучения:
1. Ridge
2. LinearRegression
3. LightGBM
4. CatBoost

Данные были предварительно разделены на тренировочную и тестовую выборку в соотношение 75:25.
Проведено масштабирование данных.
Также проведено кодирование данных тренировочной и тестовой выборки методом OHE для обучения моделей Ridge и LinearRegression.
Для обучения моделей LightGBM и CatBoost данные брали без кодирования.

В итоге для каждой модели были подобраны гиперпараметры, которые выдают RMSE меньше 2500.

Итого:

| Модель    |   Лучшие гиперпараметры | Лучшее RMSE | Время обучения и поиска гиперпараметров| 
| :---      | :----                   | :----      | :----                  | 
|  Ridge        |     alpha=0.15           |2403.62           |10min 57s              |
|LinearRegression | cv=5              |2402.4826           |4min               |
|  LightGBM        |  learning_rate=0.2, num_leaves=50,         |1388.8  |18min 36s              |
|   CatBoost    |     depth=8, iterations=50, learning_rate=0.02          |2269.4386       |2min 42s               |


Лучшие рещультаты по RMSE у LightGBM, а лучшее время по вычислению CatBoost. 


- ШАГ 3

В итоге для каждой модели были подобраны гиперпараметры, которые выдают RMSE меньше 2500.

Итого результаты с заданными гиперпараметрами:

| Модель           |   RMSE                      |  Лучшие гиперпараметры | Время обучения | Время предсказания | 
| :---             | :----                      | :----                    | :----          | :----              | 
| Ridge            |  2403.62                   | alpha=0.15                |5.83 s          |41.3 ms|
| LinearRegression |  2402.4826                 | cv=5               |	43.5 s          |3min 36s |
| LightGBM         |  1388.8                     |learning_rate=0.2, num_leaves=50        |11min 49s  |2.12 s|
| CatBoost         |  2269.4386                 |depth=8, iterations=50, learning_rate=0.02 |5.75 s         |187 ms|


Лучшие результаты по RMSE у модели LightGBM, однако моедль обучается 11 мин, что очень долго по сравнению с другими.
Следующая модель у которой минимальная RMSE и малое время исполнения и обучения и предсказания у CatBoost. Да время обучение предсказания и обучения чуть короче у Ridge, но RMSE больше. Думаю клиенту в данному случае разнича в 100ms критичной не будет, а вот показатель в RMSE будет выйгрышней. Поэтому выберем ммодель CatBoost

На тестовой выборке результаты :
- RMSE 2256.9265
- время обучения:5.75 s 
- время предсказания: 44.9 ms





